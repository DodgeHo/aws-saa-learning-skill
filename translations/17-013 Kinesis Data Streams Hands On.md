---
source: 17 - Decoupling applications SQS, SNS, Kinesis, Active MQ\013 Kinesis Data Streams Hands On_zh.srt
---

教师：让我们继续练习Kinesis数据流｡

我将打开Kinesis服务, 并创建第一个Kinesis数据流｡

我们可以看到, 这里有三个选项｡ 

我们可以使用Data Streams､ Data Firehose或Data

Analytics, 但目前我们只了解Data Streams,

所以我们继续｡

我们得到了一些关于定价的信息,

即每个碎片, 我们支付0美元｡ 05之间｡ 

好吧, 我会的

此外, 制作PUT或将数据发送到Kinesis数据流也会产生成本｡

因此, 我们将创建一个数据流,

并将其命名为DemoStream,

然后定义数据流容量｡

如您所见, 我们有两种模式,

即按需模式和资源调配模式｡

在按需模式下,

您不必考虑容量, 它会自动为您进行扩展,

因此, 如果您使用增强的扇出选项,

则每个用户的最大吞吐量为每秒200 MB, 每秒200,

000条记录, 最大读取容量为每秒400 MB｡

因此按需作为按吞吐量付费的定价模式, 但没有免费层｡

好吧, 我会的

此外, “资源调配”模式也没有可用层｡ 

在供应模式下, 您需要供应碎片｡ 

如果您想了解需要多少碎片, 可以使用碎片估计器工具,

它基于每秒发送的记录数量､ 记录大小以及拥有的消费者数量｡

好吧, 我会的

但在一个示例中, 我们将只设置一个分片｡ 

一个碎片可以让我们每秒写入1MB,

每秒读取2MB｡

很明显, 如果你放10个碎片,

那么所有的东西都乘以10｡ 好的, 一个碎片就足够我们做演示了.

这也是我们能找到的最便宜的选择｡ 

如果你不想支付任何钱在这门课上, 然后不要这样做的手,

因为你会支付一些钱为您的碎片,

虽然我们会处理它, 然后删除它足够快｡

当你准备好了, 你只需点击Create data stream,

然后等待数据流被创建｡

我们的流现在已成功创建｡ 

所以在应用方面, 我们可以看到,

我们有生产商, 我们被推荐了三个选择｡

Kinesis代理､ SDK或Kinesis Producer库｡

所以它们都可以在GitHub上找到, 你可以去看看｡ 

这是一种将数据从应用程序服务器流式传输到Kinesis数据流的方法｡

SDK用于在非常低的级别上开发生产者｡ 

而KPL是让你开发一个非常高水平的生产者,

有一个更好的API｡

在消费者方面, 我们有Kinesis

Data Analytics､ Kinesis Data Firehose､

Kinesis客户端库或Lambda, 这些都不是这里显示的选项｡

好吧, 我会的 我们获得了一些有关Kinesis数据流的监测信息｡

我们要发送多少条记录？

我们可以看看配置｡ 

所以如果你想缩放流, 我们可以说我们想要多少碎片｡

我们可以从一个, 比如说,

五个, 扩展我们的运动数据流｡

我们可以添加一些标记,

然后使用增强型扇出并对其进行配置,

如果我们希望某些消费者应用程序利用增强型扇出功能的话｡

但现在, 让我们保持简单｡ 

我们只想写入和读取我们的流, 因此,

我们将使用SDK进行生产和消费｡

为此, 我们需要打开一个CLI, 让我们使用CloudShell,

因为它很有趣｡

我将单击此处的CloudShell,

它是钟形图标旁边的图标｡

而这个就要打开了, 对我来说, ｡ 

AWS中的命令行界面｡ 

作为替代方案, 您可以使用自己的终端或CLI（如果已预先配置）,

但我喜欢切换, 我真的很喜欢这个, 因为至少涉及的配置较少｡

第一次创建环境可能需要一点时间,

而且CloudShell在AWS上是免费的, 所以不用担心｡

与此同时, 在Kinesis上, 打开Kinesis数据流｡

sh文件,

我们将使用它｡

因此, 根据AWS CLI的CLI版本,

有两种类型的命令可写入Kinesis数据流｡

通常情况下, 您安装了第二个版本,

但也有可能安装了第一个版本｡

您只需输入aws

--version并粘贴, 即可获得版本, 然后,

您将获得有关AWS CLI版本的一些信息｡

因此, 在CloudShell中, 将要安装的CLI版本是第2版,

正如您在此处看到的, 它是CLI第2版｡

1. 16,

因此我们将使用CLI命令版本2｡

但是如果你想拥有第一个版本,

那么你就会使用这些注释｡

好吧, 我会的 现在我们可以走了｡ 

我们首先要做的是将一个记录发送到Kinesis数据流中｡

为此, 有一个名为put-record的API｡ 

和put-record, 我们需要指定一个流名称｡ 

在本例中, 我没有将流命名为test, 而是将其命名为DemoStream,

因此我们必须在CLI命令中对此进行更改, 但您已经明白了｡

然后为数据设置指定分区键｡ 

因此, 用户1, 请记住, 共享同一分区密钥的数据将转到同一个分片,

但我们只有一个分片, 因此在本例中这并不重要｡

然后是数据本身, 所以用户注册｡ 

最后, 因为我们要写一些文本数据, 所以需要使用cli-binary-format

raw-in-base64-out选项｡

好吧, 我会的 让它粘贴这个命令, 复制粘贴,

但让我编辑流名称, 以确保它是DemoStream｡

云通道会自动配置您自己的IM凭据,

因此它将继承您的IM凭据,

而且默认情况下, 我们将使用它启动的区域｡

所以美东一号｡ 

我按下Enter键｡ 

而现在, 我们得到了一条成功的消息｡ 

因此, 该消息被发送为shardId-000000000000｡ 

所以我们的第一个分片, 消息的序列号在这里｡

如果我再做一次, 我会收到第二条成功的消息, 这样我们就可以进行用户注册了｡

我们可以将消息混在一起,

然后是用户登录, 然后可能是用户注销｡

所以我们只是, 我们只是设置一些消息到我们的运动数据流｡

好极了｡  我将清除此选项, 如果您稍等片刻,

然后进入监控, 查看流指标, 我会将其设置为一小时,

您会在此处看到一条放置记录, 但更新CloudWatch指标需要一点时间, 但您会在此处看到它｡

好吧, 我会的

接下来, 我们希望能够使用Kinesis数据流｡

为此, 我们将首先描述流, 以获得有关此流由什么组成的一些信息,

因为我们需要能够从特定的碎片中使用｡

这是DemoStream, 我将按Enter键, 正如您在这里看到的, 我们有这个StreamDescription｡

我们有一个名为shardId-0000000000000的碎片,

因此我们需要记住它｡ 好吧, 我会的

才能从这个流中读取｡ 

因此, 当您使用CLI时,

SDK处于非常非常低的级别,

您需要指定从哪个分片读取｡

但如果您使用的是Kinesis客户端库,

所有这些都将由库本身为您处理｡

但是我们使用的是CLI,

所以我们必须指定分片ID｡

所以我按Q键退出, 我将使用一些数据｡

我要运行这个命令, 就在这里,

让我清除它｡

有两件事需要注意,

第一, 我需要更改正在使用的流的名称｡

所以DemoStream是一个流, 然后shard-iterator-type是TRIM-HORIZON｡

这意味着你将从流的最开始读取, 所以它将从开始读取所有发送的记录｡

另一个选项是, 确保仅接收从新启动到CLI命令的那一刻起的记录｡

不管怎样, 我现在要按回车键｡ 

这将给我一个ShardIterator｡ 

这个ShardIterator可以被重用来使用记录, 所以下一个API注释是kinesis

get-records --shard-iterator｡

然后, 我们在这里指定整个字符串｡ 

因此, 我现在正在使用的这种消费模式,

通过使用低级别API, 描述流,

获取ShardIterator,

并获取记录, 使用的是共享消费模式｡

这不是使用增强的扇出,

在我看来, 应该使用Kinesis客户端库,

消费者库, 让你真正利用, 并有一个很好的API这样做｡

但这是低级的｡ 

我们单击并按下Kinesis get-records上的Enter键,

我们将从中获得一批记录｡

我们曾经在这里有一条记录, 它是PartitionKey

user1｡

我们这里有一些数据, 但都是base64编码的｡ 

我们还有另一个数据, base64编码｡ 

我们得到一些时间戳信息, 另一个数据,

base64编码｡

然后如果我按回车键,

它会下降一点｡

更多base64编码的数据｡ 

为了确保我们能够读取数据,

我可以访问网站, 在线进行base 64解码,

我将把这些数据粘贴到这里, 进入base

64解码, 然后单击"解码“, 这将为我们提供用户注册信息｡

如果我粘贴第二种类型的数据,

这个, 复制并粘贴到这里, 将提供用户登录｡

所以我们哪是我们派的｡ 

那就完美了｡ 

一切正常｡ 

然后, 正如你所看到的,

这里有一个NextShardIterator参数｡

因此, 下次使用时, 我们需要指定此NextShardIterator参数,

以便从停止使用的位置开始使用｡

因此, 这是您必须在代码中迭代的内容｡ 

但在低水平上, 我们已经产生了数据到Kinesis数据流,

并从Kinesis数据流消费数据, 这是真棒｡

同时, 我们还使用了CloudShell,

我认为它非常方便｡

这就是本演示的全部内容,

请保持此流处于打开状态, 因为我们稍后将在Kinesis

Data Firehose中使用此流｡

我们下节课再见｡
